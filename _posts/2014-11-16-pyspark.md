---
titile: "MapReduce & Spark in Python"
date: 2014-11-16 16:22:11
description: Spark notes on Pycon
---
##TOPICs##
1. 数据处理的框架模型: map, shuffle, reduce
2. 任务处理及调度: spark
3. 基本的数据处理算法支持: pyspark
4. 加速数据逻辑运算过程: pyopencl

###1. 数据处理的框架模型: map, shuffle, reduce
functools.reduce(fucntion, iterable[, initializer])
Apply function of two arguments cumulatively to the items of sequence, from left to right, so as to reduce the sequence to a single value.  

`reduce(lambda x, y: x+y, [1, 2, 3, 4, 5])` calculates ((((1+2)+3)+4)+5)

map(function, iterable, ...)
Return an iterator that applies function to every item of iterable, yielding the results. If additional iterable arguments are passed, function must take that many arguments and is applied to the items from all iterables in parallel. With multiple iterables, the iterator stops when the shortest iterable is exhausted.
`map(lambda x : x + x, [1,2,3,4,5])`

###2. 任务处理及调度: spark
* Streaming, Spark SQL, MLLib, GraphX
* RDD
* HDFS

###3. 基本的数据处理算法支持: pyspark
####蒙特卡洛方法
>蒙特·卡罗方法（Monte Carlo method），也称统计模拟方法，是二十世纪四十年代中期由于科学技术的发展和电子计算机的发明，而被提出的一种以概率统计理论为指导的一类非常重要的数值计算方法。是指使用随机数（或更常见的伪随机数）来解决很多计算问题的方法。用统计方法把模型的数字特征估计出来，从而得到实际问题的数值解。与它对应的是确定性算法。蒙特·卡罗方法在金融工程学，宏观经济学，计算物理学（如粒子输运计算、量子热力学计算、空气动力学计算）等领域应用广泛。

**蒙特卡洛求pi**

    def f(_):
        x = random() * 2 - 1
        y = random() * 2 - 1
        return 1 if x ** 2 + y ** 2 < 1 else 0

    count = sc.parallelize(xrange(1, n+1), slices).map(f).reduce(add)
    print "Pi is roughly %f" % (4.0 * count / n)

    sc.stop()

###4.  加速数据逻辑运算过程

>OpenCL (Open Computing Language) is an open royalty-free standard for general purpose parallel programming across CPUs, GPUs and other processors, giving software developers portable and efficient access to the power of these heterogeneous processing platforms.  

[Tutorials for OpenCL in Chinese](http://www.cnblogs.com/mikewolf2002/archive/2012/01/30/2332356.html)
>PyOpenCL lets you access GPUs and other massively parallel compute devices from Python.
